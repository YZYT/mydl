{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d2l.init_Seed()\n",
    "device = d2l.get_device()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU ready!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "config = {\n",
    "    \"n_train\": 100,\n",
    "    \"n_test\": 100,\n",
    "    \"max_degree\": 20,\n",
    "    \"train_degree\": 4,\n",
    "    \"batch_size\": 10,\n",
    "    \"n_epochs\": 60,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    # \"optimizer\": \"Adam\",\n",
    "    # \"optimizer\": \"Adagrad\",\n",
    "    # \"optimizer\": \"Adadelta\",\n",
    "    \"optim_hparas\": {\n",
    "        'lr': 0.01,         # for SGD and Adam\n",
    "#         'momentum': 0.9,\n",
    "#         'nesterov':True\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def poly(x, w):\n",
    "    max_degree = len(true_w)\n",
    "    features = x.pow(torch.arange(max_degree))\n",
    "    for i in range(max_degree):\n",
    "        features[:, i] /= math.gamma(i + 1)\n",
    "    # print(features.shape, w.shape)\n",
    "\n",
    "    return features @ w\n",
    "\n",
    "\n",
    "def initial(true_w, n_train=100, n_test=100):\n",
    "    X = torch.randn((n_train + n_test, 1))\n",
    "    y = poly(X, true_w)\n",
    "    y += torch.normal(0, 0.2, y.shape)\n",
    "\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "true_w = torch.zeros(config['max_degree'])\n",
    "true_w[0:4] = torch.tensor([5, 1.2, -3.4, 5.6])\n",
    "X, y = initial(true_w, n_train=config['n_train'], n_test=config['n_test'])\n",
    "tr_set = d2l.prep_dataloader(X[:, :config['train_degree']], y, 'train', config['batch_size'])\n",
    "te_set = d2l.prep_dataloader(X[:, config['train_degree']:], y, 'test', config['batch_size'])\n",
    "X[:, :config['train_degree']].shape\n",
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X.numpy(), y.numpy(), c='red', s=2)\n",
    "\n",
    "x = torch.linspace(-2, 3, 20).reshape(-1, 1)\n",
    "ax.plot(x.numpy(), poly(x, true_w).numpy())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1f2712af0>]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_degree):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(nn.Linear(input_degree, 1, bias=False))\n",
    "        \n",
    "        def init_weights(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "        # self.net[0].weight.data.fill_(-1.5)\n",
    "        # self.net[0].weight.data = torch.tensor([[-1., -1.]])\n",
    "        self.net.apply(init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X).squeeze(1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def dev_reg(net, dv_set, loss, device='cpu'):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "    \n",
    "    metric = torch.zeros(2)\n",
    "\n",
    "    for X, y in dv_set:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_hat = net(X)\n",
    "            metric += torch.tensor([loss(y_hat, y).cpu().item() * len(y), y.numel()])\n",
    "\n",
    "    return float(metric[0] / metric[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def train_reg(model, tr_set, te_set, loss, optimizer, lr_scheduler=None, device='cpu', n_epochs=10, early_stop=5):\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    loss_record = {\"train\": [], \"dev\": []}\n",
    "\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, n_epochs], ylim=[0, 1],\n",
    "                        legend=['train loss', 'test loss'],\n",
    "                        figsize=(6, 6))\n",
    "    \n",
    "    min_loss = 1000.\n",
    "    \n",
    "    while epoch < n_epochs:\n",
    "        model.train()\n",
    "        for X, y in tr_set:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(model(X), y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_record['train'].append(l.detach().cpu().item())\n",
    "        \n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "        epoch += 1\n",
    "        \n",
    "        train_l = dev_reg(model, tr_set, loss, device)\n",
    "        dev_l = dev_reg(model, tr_set, loss, device)\n",
    "        \n",
    "        if dev_l < min_loss:\n",
    "            min_loss = dev_l\n",
    "        \n",
    "        animator.add(epoch, (train_l, dev_l))\n",
    "        loss_record['dev'].append(dev_l)\n",
    "#         print(f\"epoch: {epoch:3d}, train loss: {train_l: .4f}, dev loss: {dev_l:.4f}\")\n",
    "    \n",
    "    return min_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "loss = nn.MSELoss(reduction='mean')\n",
    "model = MLP(input_degree=config['train_degree']).to(device)\n",
    "optimizer = getattr(torch.optim, config[\"optimizer\"])(\n",
    "    model.parameters(), **config[\"optim_hparas\"]\n",
    ")\n",
    "\n",
    "# lr_scheduler = getattr(torch.optim.lr_scheduler, config[\"lr_scheduler\"])(optimizer, **config[\"lr_sched_hparas\"])\n",
    "\n",
    "min_loss = train_reg(model, tr_set, te_set, loss, optimizer, None, device, config['n_epochs'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " ** On entry to SGEMM  parameter number 10 had an illegal value\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7840/3424251296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# lr_scheduler = getattr(torch.optim.lr_scheduler, config[\"lr_scheduler\"])(optimizer, **config[\"lr_sched_hparas\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7840/1042888009.py\u001b[0m in \u001b[0;36mtrain_reg\u001b[0;34m(model, tr_set, te_set, loss, optimizer, lr_scheduler, device, n_epochs, early_stop)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7840/424293532.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"361.037344pt\" version=\"1.1\" viewBox=\"0 0 380.054687 361.037344\" width=\"380.054687pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-09-08T23:36:53.573661</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 361.037344 \nL 380.054687 361.037344 \nL 380.054687 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 337.159219 \nL 364.903125 337.159219 \nL 364.903125 10.999219 \nL 30.103125 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mddc43f7032\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mddc43f7032\" y=\"337.159219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(22.151563 351.757656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.063125\" xlink:href=\"#mddc43f7032\" y=\"337.159219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g transform=\"translate(89.111563 351.757656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"164.023125\" xlink:href=\"#mddc43f7032\" y=\"337.159219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g transform=\"translate(156.071563 351.757656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.983125\" xlink:href=\"#mddc43f7032\" y=\"337.159219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g transform=\"translate(223.031563 351.757656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"297.943125\" xlink:href=\"#mddc43f7032\" y=\"337.159219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g transform=\"translate(289.991563 351.757656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.903125\" xlink:href=\"#mddc43f7032\" y=\"337.159219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g transform=\"translate(356.951563 351.757656)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"meafc582741\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#meafc582741\" y=\"337.159219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 340.958438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#meafc582741\" y=\"271.927219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 275.726438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#meafc582741\" y=\"206.695219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 210.494438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#meafc582741\" y=\"141.463219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 145.262437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#meafc582741\" y=\"76.231219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 80.030438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#meafc582741\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 337.159219 \nL 30.103125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 337.159219 \nL 364.903125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 337.159219 \nL 364.903125 337.159219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 10.999219 \nL 364.903125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for X, y in tr_set:\n",
    "    print(X.shape)\n",
    "    \n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10  ('py38': conda)"
  },
  "interpreter": {
   "hash": "b1d710d4a2dd0e836743a9708dcf2dd87750cb6db75a03dbc0a1931aaec4e6cb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}